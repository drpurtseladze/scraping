{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates how to use Selenium webdriver to automatically download and parse search results from indeed.com.\n",
    "I will be using Firefox as my browser of choice.\n",
    "\n",
    "First we need to install BeautifulSoup and Selenium libraries. We need BeautifulSoup to extract text enclosed by certain HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\datka\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\datka\\anaconda3\\lib\\site-packages (from selenium) (1.24.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\datka\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\datka\\anaconda3\\lib\\site-packages (from bs4) (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\datka\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install selenium\n",
    "!{sys.executable} -m pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to download the latest version of geckodriver so we can control Firefox windows from python.\n",
    "\n",
    "It can be downoaded from here:\n",
    "https://github.com/mozilla/geckodriver/releases\n",
    "    \n",
    "Unzip the file and remember its location. In this example I am using \"c:/geckodriver/geckodriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the webdriver, let us specify some parameters that will make monitoring and debugging process easier.\n",
    "\n",
    "<b>options.headless = False</b>\n",
    "\n",
    "Opens a firefox window that is controlled by python. We can use the window as if it were a regular firefox window, we can scroll, click on links, view page source, inspect elements etc.\n",
    "\n",
    "<b>pageLoadStrategy = 'normal'</b>\n",
    "\n",
    "Default option, we will be able to interact with the partially loaded page.\n",
    "\n",
    "<b>driver.set_page_load_timeout(10)</b>\n",
    "\n",
    "Set page load timeout to 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Selenium Firefox Webdriver...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "print('Starting Selenium Firefox Webdriver...')\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "\n",
    "caps = DesiredCapabilities().FIREFOX\n",
    "caps['pageLoadStrategy'] = 'normal'\n",
    "\n",
    "options = Options()\n",
    "options.headless = False\n",
    "\n",
    "\n",
    "driver = webdriver.Firefox(executable_path = 'c:/geckodriver/geckodriver.exe', options=options, capabilities=caps)\n",
    "driver.set_page_load_timeout(10)\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking for Data Sciene jobs in Texas.\n",
    "\n",
    "To do so, we open a new browser window, go to indeed.com, specify job title: Data Scientist, Location: Texas. Click Find jobs. \n",
    "Address bar should change to the following string:\n",
    "\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/jobs?q=data+scientist&l=Texas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open url\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed is going to ask you for your location/registration. Politely decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Find the \"no, thanks\" link, click on it.\n",
    "    no_thanks = driver.find_element_by_link_text('No, thanks')\n",
    "    no_thanks.click()\n",
    "    print('Closing the pop-up asking for location/registration')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We are remotely controlling a firefox window from python. \n",
    "Now it is time to figure out the structure of the page. We see that each job listing is enclosed in a box.\n",
    "Right click the box and select \"inspect element\". \n",
    "\n",
    "<img src=\"job_container.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each box is an html container that has a multi level structure:\n",
    "    \n",
    "Top level: <div id=\"...\" class = \"jobsearch-SerpJobCard unifiedRow row result clickcard\" data-jk = \"...\" ...>\n",
    "\n",
    "To locate each box we use find_elements_by_xpath method:\n",
    "\n",
    "We are looking for a <b>div</b> container that has a <b>class</b> attribute with the value of <b>\"jobsearch-SerpJobCard unifiedRow row result clickcard\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = \"//div[contains(@class, 'jobsearch-SerpJobCard unifiedRow row result clickcard')]\"\n",
    "job_elements = driver.find_elements_by_xpath(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to see the job desciption we need to click on the box, the desciption will appear in the right half of the screen.\n",
    "\n",
    "Let's simulate clicking on the first job listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elements[0].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page loads and shows only one job description at a time, we need to simulate clicks and extract the text.\n",
    "Once again we right click on the description and choose \"Inspect element\". It has a very simple structure.\n",
    "\n",
    "div id=\"vjs-desc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This time we use beautiful soup, because we no longer need to interact with the page. Beautiful can get rid of the html tags and clean the text for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get page source\n",
    "src = driver.page_source\n",
    "soup = BeautifulSoup(src)\n",
    "description = soup.find('div', {\"id\": \"vjs-desc\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMMEDIATE NEED FOR A DATA ENGINEER/SCIENTIST DATA STRUCTURES - Dallas or San DiegoHealth IQ is adding a Data Engineer to its growing Business Intelligence team. As a Data Engineer, you will work with clients, team members, department heads and 3rd party data providers, to develop, maintain, and enhance our data engineering capabilities in support of our data and predictive analytic offerings to the insurance marketplace. The ideal candidate demonstrates a curious analytical mind with the ability'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.get_text()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get page source\n",
    "src = driver.page_source\n",
    "soup = BeautifulSoup(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs on current page: 19\n",
      "0 Senior Statistician and Software Developer\n",
      "1 Quantitative Analyst Lead/Model Development\n",
      "2 Lead Data Scientist-NLP Expert\n",
      "3 Modeling Analyst\n",
      "4 Decision Science Analyst\n",
      "5 Machine Learning - Artificial Intelligence Architect\n",
      "6 Data Scientist III (B3)\n",
      "7 Artificial Intelligence Researcher\n",
      "8 Senior Data Scientist\n",
      "9 Clinical Data Scientist\n",
      "10 NLP Engineer\n",
      "11 Data Scientist / Statistician\n",
      "12 Artificial Intelligence Engineer\n",
      "13 Data Science Engineer\n",
      "14 Geospatial Software Developer and Data Scientist\n",
      "15 Data Analyst Specialist\n",
      "16 Decision Science Analyst Senior\n",
      "17 Decision Science Analyst Lead\n",
      "18 Sr. Data Analyst\n",
      "Jobs on current page: 17\n",
      "19 Data Scientist Lead\n",
      "20 Data Scientist Senior\n",
      "21 Data Scientist I\n",
      "22 Statistician and Software Developer\n",
      "23 Data Scientist / AI Engineer\n",
      "24 Artificial Intelligence Engineer\n",
      "25 Quantitative Researcher\n",
      "26 Data Scientist - Nationwide Opportunities\n",
      "27 Data Scientist\n",
      "28 Data Scientist\n",
      "29 Data Scientist\n",
      "30 Machine Learning Architectures and Acceleration Researcher (...\n",
      "31 Data Science Engineer\n",
      "32 Staff Data Scientist - Technology - Large Scale Financial Fo...\n",
      "33 Decision Science Analyst Senior\n",
      "34 Decision Science Analyst I - Enterprise Advice Group -\n",
      "35 Quantitative Analyst Lead/Model Development\n"
     ]
    }
   ],
   "source": [
    "j=[]\n",
    "\n",
    "while len(j)<20:\n",
    "    xp = \"//div[contains(@class, 'jobsearch-SerpJobCard unifiedRow row result clickcard')]\"\n",
    "    # find job containers on current page\n",
    "    job_elements = driver.find_elements_by_xpath(xp)\n",
    "    print('Jobs on current page:', len(job_elements))\n",
    "    \n",
    "    # click on every job posting on current page\n",
    "    for element in job_elements:\n",
    "        \n",
    "        # make sure the are not bugging you with regisration, politely decline.\n",
    "        try:\n",
    "            no_thanks = driver.find_element_by_link_text('No, thanks')\n",
    "            no_thanks.click()\n",
    "            print('Closing the pop-up asking for location/registration')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        element.click()\n",
    "\n",
    "        # job description\n",
    "        src = driver.page_source\n",
    "        soup = BeautifulSoup(src)\n",
    "        description = soup.find('div', {\"id\": \"vjs-desc\"}) \n",
    "\n",
    "\n",
    "        # company and locations\n",
    "\n",
    "        cl = element.find_elements_by_class_name('sjcl')\n",
    "\n",
    "        if len(cl)>0:\n",
    "            company_location = cl[0].text\n",
    "        else:\n",
    "            company_location = None    \n",
    "\n",
    "\n",
    "        # title\n",
    "        t = element.find_elements_by_class_name('title')\n",
    "\n",
    "        if len(cl)>0:\n",
    "            title = t[0].text\n",
    "        else:\n",
    "            title = None\n",
    "\n",
    "        # salary\n",
    "        s = element.find_elements_by_class_name('salarySnippet.holisticSalary')\n",
    "        if len(s)>0:\n",
    "            salary = s[0].text\n",
    "        else:\n",
    "            salary = None\n",
    "        print(len(j),title)\n",
    "        j.append((title, company_location, salary, description.get_text()))\n",
    "        \n",
    "    # click next to view more postings\n",
    "    next_link = driver.find_elements_by_partial_link_text('Next')[-1]\n",
    "    next_link.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBS = pd.DataFrame(j, columns = ['title', 'company_location','salary','description'])\n",
    "JOBS_CL = JOBS['company_location'].str.split('\\n', expand = True)\n",
    "JOBS_CL.columns = ['company/rating', 'location']\n",
    "JOBS = pd.concat([JOBS.drop(columns = 'company_location'), JOBS_CL], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>company/rating</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Statistician and Software Developer</td>\n",
       "      <td>None</td>\n",
       "      <td>StataCorp is seeking a person with a good unde...</td>\n",
       "      <td>StataCorp 4.0</td>\n",
       "      <td>College Station, TX 77845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Quantitative Analyst Lead/Model Development</td>\n",
       "      <td>None</td>\n",
       "      <td>Purpose of Job We are currently seeking a tale...</td>\n",
       "      <td>USAA 3.9</td>\n",
       "      <td>Austin, TX 78701 (Downtown area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lead Data Scientist-NLP Expert</td>\n",
       "      <td>None</td>\n",
       "      <td>Purpose of Job The candidate selected for this...</td>\n",
       "      <td>USAA 3.9</td>\n",
       "      <td>San Antonio, TX 78206 (King William area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Modeling Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Purpose of Job We are currently seeking a tale...</td>\n",
       "      <td>USAA 3.9</td>\n",
       "      <td>San Antonio, TX 78206 (King William area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Decision Science Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Purpose of Job We are currently seeking a tale...</td>\n",
       "      <td>USAA 3.9</td>\n",
       "      <td>San Antonio, TX 78206 (King William area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Machine Learning - Artificial Intelligence Arc...</td>\n",
       "      <td>None</td>\n",
       "      <td>Interview Location: Georgetown, TX\\n\\nJob Titl...</td>\n",
       "      <td>Loram Maintenance of Way 3.2</td>\n",
       "      <td>Georgetown, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist III (B3)</td>\n",
       "      <td>None</td>\n",
       "      <td>The Data Scientist job expectations (typically...</td>\n",
       "      <td>Applied Materials Inc. 3.9</td>\n",
       "      <td>Austin, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Artificial Intelligence Researcher</td>\n",
       "      <td>$250,000 - $450,000 a year</td>\n",
       "      <td>As an Artificial Intelligence Researcher, you ...</td>\n",
       "      <td>Axiom Group 2.7</td>\n",
       "      <td>Austin, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Job requirements/ skills:﻿\\nMaster’s degree wi...</td>\n",
       "      <td>Data Quantist</td>\n",
       "      <td>Austin, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Clinical Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "      <td>Booz Allen Hamilton 3.9</td>\n",
       "      <td>San Antonio, TX 78205 (Downtown area)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         Senior Statistician and Software Developer   \n",
       "1        Quantitative Analyst Lead/Model Development   \n",
       "2                     Lead Data Scientist-NLP Expert   \n",
       "3                                   Modeling Analyst   \n",
       "4                           Decision Science Analyst   \n",
       "5  Machine Learning - Artificial Intelligence Arc...   \n",
       "6                            Data Scientist III (B3)   \n",
       "7                 Artificial Intelligence Researcher   \n",
       "8                              Senior Data Scientist   \n",
       "9                            Clinical Data Scientist   \n",
       "\n",
       "                       salary  \\\n",
       "0                        None   \n",
       "1                        None   \n",
       "2                        None   \n",
       "3                        None   \n",
       "4                        None   \n",
       "5                        None   \n",
       "6                        None   \n",
       "7  $250,000 - $450,000 a year   \n",
       "8                        None   \n",
       "9                        None   \n",
       "\n",
       "                                         description  \\\n",
       "0  StataCorp is seeking a person with a good unde...   \n",
       "1  Purpose of Job We are currently seeking a tale...   \n",
       "2  Purpose of Job The candidate selected for this...   \n",
       "3  Purpose of Job We are currently seeking a tale...   \n",
       "4  Purpose of Job We are currently seeking a tale...   \n",
       "5  Interview Location: Georgetown, TX\\n\\nJob Titl...   \n",
       "6  The Data Scientist job expectations (typically...   \n",
       "7  As an Artificial Intelligence Researcher, you ...   \n",
       "8  Job requirements/ skills:﻿\\nMaster’s degree wi...   \n",
       "9  The Challenge:\\nAre you excited at the prospec...   \n",
       "\n",
       "                 company/rating                                   location  \n",
       "0                 StataCorp 4.0                  College Station, TX 77845  \n",
       "1                      USAA 3.9           Austin, TX 78701 (Downtown area)  \n",
       "2                      USAA 3.9  San Antonio, TX 78206 (King William area)  \n",
       "3                      USAA 3.9  San Antonio, TX 78206 (King William area)  \n",
       "4                      USAA 3.9  San Antonio, TX 78206 (King William area)  \n",
       "5  Loram Maintenance of Way 3.2                             Georgetown, TX  \n",
       "6    Applied Materials Inc. 3.9                                 Austin, TX  \n",
       "7               Axiom Group 2.7                                 Austin, TX  \n",
       "8                 Data Quantist                                 Austin, TX  \n",
       "9       Booz Allen Hamilton 3.9      San Antonio, TX 78205 (Downtown area)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOBS.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
